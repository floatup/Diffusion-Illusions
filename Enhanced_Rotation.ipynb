{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aad178dc-68e5-4e67-811d-46360f8cd385",
   "metadata": {},
   "source": [
    "这是2025秋北京大学CV的Final Project，我们选择对当前的Diffusion Illusion进行改进，以期待能够产出更有创造力的作品。这个juypter notebook的目标是创造对于两张图片，更加细化的旋转能够产出不同的图片，甚至产出故事的效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb36d8b-a491-4546-9246-113ee3f3d83e",
   "metadata": {},
   "source": [
    "以下的大多数编程块都是直接由项目粘贴过来，而如果有自己修改的部分，我会做出标识以供debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b47ba46-51a4-46d9-a745-1ab7cb3346c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [ ! -d \".git\" ]; then \n",
    "    rm -rf * .*; #Get rid of Colab's default junk files\n",
    "    git clone -b master https://github.com/dreaveler/Diffusion-Illusions.git .\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f522b2ad-d842-46ca-bb55-a9bbe3273615",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade -r requirements.txt\n",
    "%pip install rp --upgrade\n",
    "# You may need to restart the runtime after installing these\n",
    "# I'm not sure why this helps, but all sorts of weird random errors pop up in Colab if you don't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302f93b3-8659-4234-a46d-f0fe121af005",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rp\n",
    "import torch\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision.transforms import InterpolationMode\n",
    "import torch.nn as nn\n",
    "import source.stable_diffusion as sd\n",
    "from easydict import EasyDict\n",
    "from source.learnable_textures import LearnableImageFourier\n",
    "from source.stable_diffusion_labels import NegativeLabel\n",
    "from itertools import chain\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a744d62b-f176-4247-9055-d6e3313e5022",
   "metadata": {},
   "source": [
    "下面会是第一个需要修改的部分 关于prompts 我暂时的想法是两张图片的旋转离散到8个角度去，这样可以保证中间叠加过后的图形是可控的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229595a1-bd99-49eb-a1e8-284f89d02032",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompts = rp.load_yaml_file('source/example_prompts.yaml')\n",
    "print('Available example prompts:', ', '.join(example_prompts))\n",
    "\n",
    "#These prompts are all strings - you can replace them with whatever you want! By default it lets you choose from example prompts\n",
    "prompt_a = \"A lion\"\n",
    "prompt_b = \"A cat\"\n",
    "prompt_c = \"miku\"\n",
    "prompt_d = \"dog\"\n",
    "prompt_e = \"flower\"\n",
    "prompt_f = \"Kobe Bryant\"\n",
    "prompt_g = \"snake\"\n",
    "prompt_h = \"Harry Potter\"\n",
    "\n",
    "negative_prompt = ''\n",
    "\n",
    "print()\n",
    "print('Negative prompt:',repr(negative_prompt))\n",
    "print()\n",
    "print('Chosen prompts:')\n",
    "print('    prompt_a =', repr(prompt_a))\n",
    "print('    prompt_b =', repr(prompt_b))\n",
    "print('    prompt_c =', repr(prompt_c))\n",
    "print('    prompt_d =', repr(prompt_d))\n",
    "print('    prompt_e =', repr(prompt_e))\n",
    "print('    prompt_f =', repr(prompt_f))\n",
    "print('    prompt_g =', repr(prompt_g))\n",
    "print('    prompt_h =', repr(prompt_h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e46e4ca-daba-4377-912b-25d6c427e142",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 's' not in dir():\n",
    "    model_name=\"CompVis/stable-diffusion-v1-4\"\n",
    "    gpu='cuda:0'\n",
    "    s=sd.StableDiffusion(gpu,model_name)\n",
    "device=s.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc6b833-5edf-4cab-a0bc-958a95003a7f",
   "metadata": {},
   "source": [
    "下面这部分的改动同上 由于prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dd3953-f32d-4657-bfbd-ca8c1e98f833",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_a = NegativeLabel(prompt_a,negative_prompt)\n",
    "label_b = NegativeLabel(prompt_b,negative_prompt)\n",
    "label_c = NegativeLabel(prompt_c,negative_prompt)\n",
    "label_d = NegativeLabel(prompt_d,negative_prompt)\n",
    "label_e = NegativeLabel(prompt_e,negative_prompt)\n",
    "label_f = NegativeLabel(prompt_f,negative_prompt)\n",
    "label_g = NegativeLabel(prompt_g,negative_prompt)\n",
    "label_h = NegativeLabel(prompt_h,negative_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866cfbe8-6cf6-4a89-ae34-5e0c6ce6c42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image Parametrization and Initialization (this section takes vram)\n",
    "\n",
    "#Select Learnable Image Size (this has big VRAM implications!):\n",
    "#Note: We use implicit neural representations for better image quality\n",
    "#They're previously used in our paper \"TRITON: Neural Neural Textures make Sim2Real Consistent\" (see tritonpaper.github.io)\n",
    "# ... and that representation is based on Fourier Feature Networks (see bmild.github.io/fourfeat)\n",
    "learnable_image_maker = lambda: LearnableImageFourier(height=256, width=256, hidden_dim=256, num_features=128).to(s.device); SIZE=256\n",
    "# learnable_image_maker = lambda: LearnableImageFourier(height=512,width=512,num_features=256,hidden_dim=256,scale=20).to(s.device);SIZE=512\n",
    "\n",
    "bottom_image=learnable_image_maker()\n",
    "top_image=learnable_image_maker()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4f9003-462e-4d9e-9f64-89cb235e7edc",
   "metadata": {},
   "source": [
    "下面这部分也同样需要修改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf390f57-8aaf-4169-840d-fa4d5b159dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "brightness=3\n",
    "\n",
    "CLEAN_MODE = True # If it's False, we augment the images by randomly simulating how good a random printer might be when making the overlays...\n",
    "\n",
    "def simulate_overlay(bottom, top):\n",
    "    if CLEAN_MODE:\n",
    "        exp=1\n",
    "        brightness=3\n",
    "        black=0\n",
    "    else:\n",
    "        exp=rp.random_float(.5,1)\n",
    "        brightness=rp.random_float(1,5)\n",
    "        black=rp.random_float(0,.5)\n",
    "        bottom=rp.blend(bottom,black,rp.random_float())\n",
    "        top=rp.blend(top,black,rp.random_float())\n",
    "    return (bottom**exp * top**exp * brightness).clamp(0,99).tanh()\n",
    "\n",
    "def rotate45(image,k):\n",
    "    return TF.rotate(image, angle=45*k, interpolation=InterpolationMode.BILINEAR, expand=False)\n",
    "\n",
    "\n",
    "learnable_image_a=lambda: simulate_overlay(bottom_image(), rotate45(top_image(),k=0))\n",
    "learnable_image_b=lambda: simulate_overlay(bottom_image(), rotate45(top_image(),k=1))\n",
    "learnable_image_c=lambda: simulate_overlay(bottom_image(), rotate45(top_image(),k=2))\n",
    "learnable_image_d=lambda: simulate_overlay(bottom_image(), rotate45(top_image(),k=3))\n",
    "learnable_image_e=lambda: simulate_overlay(bottom_image(), rotate45(top_image(),k=4))\n",
    "learnable_image_f=lambda: simulate_overlay(bottom_image(), rotate45(top_image(),k=5))\n",
    "learnable_image_g=lambda: simulate_overlay(bottom_image(), rotate45(top_image(),k=6))\n",
    "learnable_image_h=lambda: simulate_overlay(bottom_image(), rotate45(top_image(),k=7))\n",
    "learnable_image_names=['image_0','image_45','image_90','image_135','image_180','image_225','image_270','image_315']\n",
    "\n",
    "\n",
    "\n",
    "params=chain(\n",
    "    bottom_image.parameters(),\n",
    "    top_image.parameters(),\n",
    ")\n",
    "optim=torch.optim.SGD(params,lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b10626-5b47-47ab-baa6-7f08c5ffd99d",
   "metadata": {},
   "source": [
    "下面的代码块也需要修改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318470d6-b2ed-4517-b7a4-e830bbaf2e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "nums=[0,1,2,3,4,5,6,7]\n",
    "\n",
    "#Uncommenting one of the lines will disable some of the prompts, in case you don't want to use all four for some reason (like the Summer/Winter example)\n",
    "# nums=[0  ,2,3]\n",
    "# nums=[    2  ]\n",
    "# nums=[0,1,2]\n",
    "# nums=[1]\n",
    "# nums=[0,1]\n",
    "# nums=[0,2]\n",
    "\n",
    "\n",
    "labels=[label_a,label_b,label_c,label_d,label_e,label_f,label_g,label_h]\n",
    "learnable_images=[learnable_image_a,learnable_image_b,learnable_image_c,learnable_image_d,\n",
    "                   learnable_image_e,learnable_image_f,learnable_image_g,learnable_image_h]\n",
    "learnable_image_names=[name for name in learnable_image_names]\n",
    "\n",
    "#The weight coefficients for each prompt. For example, if we have [0,1,2,1], then prompt_w will provide no influence and prompt_y will have 1/2 the total influence\n",
    "weights=[1,1,1,1,1,1,1,1]\n",
    "\n",
    "labels=[labels[i] for i in nums]\n",
    "learnable_images=[learnable_images[i] for i in nums]\n",
    "learnable_image_names=[learnable_image_names[i] for i in nums]\n",
    "weights=[weights[i] for i in nums]\n",
    "\n",
    "weights=rp.as_numpy_array(weights)\n",
    "weights=weights/weights.sum()\n",
    "weights=weights*len(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddf1521-f6c2-4199-beb1-a5340e9f61e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For saving a timelapse\n",
    "ims=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8714ce96-598d-4bfe-8580-168a5b14921b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_display_image():\n",
    "    return rp.tiled_images(\n",
    "        [\n",
    "            *[rp.as_numpy_image(image()) for image in learnable_images],\n",
    "            rp.as_numpy_image(bottom_image()),\n",
    "            rp.as_numpy_image(top_image()),\n",
    "        ],\n",
    "        length=len(learnable_images),\n",
    "        border_thickness=0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbecee45-8bf9-45e7-93a2-249ba405d5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ITER=10000\n",
    "\n",
    "#Set the minimum and maximum noise timesteps for the dream loss (aka score distillation loss)\n",
    "s.max_step=MAX_STEP=990\n",
    "s.min_step=MIN_STEP=10 \n",
    "\n",
    "display_eta=rp.eta(NUM_ITER, title='Status: ')\n",
    "\n",
    "DISPLAY_INTERVAL = 200\n",
    "\n",
    "print('Every %i iterations we display an image in the form [[%s], [bottom_image, top_image]] where'% (DISPLAY_INTERVAL, ', '.join(learnable_image_names)))\n",
    "image_defs={\n",
    "    'image_0': 'bottom_image * rotate45(top_image, k=0)',\n",
    "    'image_45': 'bottom_image * rotate45(top_image, k=1)',\n",
    "    'image_90': 'bottom_image * rotate45(top_image, k=2)',\n",
    "    'image_135': 'bottom_image * rotate45(top_image, k=3)',\n",
    "    'image_180': 'bottom_image * rotate45(top_image, k=4)',\n",
    "    'image_225': 'bottom_image * rotate45(top_image, k=5)',\n",
    "    'image_270': 'bottom_image * rotate45(top_image, k=6)',\n",
    "    'image_315': 'bottom_image * rotate45(top_image, k=7)',\n",
    "}\n",
    "for name in learnable_image_names:\n",
    "    print(f'    {name} = {image_defs[name]}')\n",
    "print()\n",
    "print('Interrupt the kernel at any time to return the currently displayed image')\n",
    "print('You can run this cell again to resume training later on')\n",
    "print()\n",
    "print('Please expect this to take hours to get good images (especially on the slower Colab GPU\\'s! The longer you wait the better they\\'ll be')\n",
    "\n",
    "try:\n",
    "    for iter_num in range(NUM_ITER):\n",
    "        display_eta(iter_num) #Print the remaining time\n",
    "\n",
    "        preds=[]\n",
    "        for label,learnable_image,weight in rp.random_batch(list(zip(labels,learnable_images,weights)), batch_size=1):\n",
    "            pred=s.train_step(\n",
    "                label.embedding,\n",
    "                learnable_image()[None],\n",
    "\n",
    "                #PRESETS (uncomment one):\n",
    "                noise_coef=.1*weight,guidance_scale=60,#10\n",
    "                # noise_coef=0,image_coef=-.01,guidance_scale=50,\n",
    "                # noise_coef=0,image_coef=-.005,guidance_scale=50,\n",
    "                # noise_coef=.1,image_coef=-.010,guidance_scale=50,\n",
    "                # noise_coef=.1,image_coef=-.005,guidance_scale=50,\n",
    "                # noise_coef=.1*weight, image_coef=-.005*weight, guidance_scale=50,\n",
    "            )\n",
    "            preds+=list(pred)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            if iter_num and not iter_num%(DISPLAY_INTERVAL*50):\n",
    "                #Wipe the slate every 50 displays so they don't get cut off\n",
    "                from IPython.display import clear_output\n",
    "                clear_output()\n",
    "\n",
    "            if not iter_num%DISPLAY_INTERVAL:\n",
    "                im = get_display_image()\n",
    "                ims.append(im)\n",
    "                rp.display_image(im)\n",
    "\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "except KeyboardInterrupt:\n",
    "    print()\n",
    "    print('Interrupted early at iteration %i'%iter_num)\n",
    "    im = get_display_image()\n",
    "    ims.append(im)\n",
    "    rp.display_image(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b913f16-005a-4925-b8d9-0c70629fab20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Bottom image:')\n",
    "rp.display_image(rp.as_numpy_image(factor_base()))\n",
    "\n",
    "print('Top image:')\n",
    "rp.display_image(rp.as_numpy_image(factor_rotator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8753a4d-1eb0-4eab-853a-52304c5d01dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_run(name):\n",
    "    folder=\"untracked/rotator_multiplier_runs/%s\"%name\n",
    "    if rp.path_exists(folder):\n",
    "        folder+='_%i'%time.time()\n",
    "    rp.make_directory(folder)\n",
    "    ims_names=['ims_%04i.png'%i for i in range(len(ims))]\n",
    "    with rp.SetCurrentDirectoryTemporarily(folder):\n",
    "        rp.save_images(ims,ims_names,show_progress=True)\n",
    "    print()\n",
    "    print('Saved timelapse to folder:',repr(folder))\n",
    "    \n",
    "save_run('untitled') #You can give it a good custom name if you want!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
